{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importando Bibliotecas e Carregando o Dataset\n"
      ],
      "metadata": {
        "id": "eXq0Pzl-Y7ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "file_path = '/content/CONSUMO_2024.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "H4q5samvdQNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Exploração e análise do dataset\n"
      ],
      "metadata": {
        "id": "jtNwOZoMdRHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()\n",
        "\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "label_encoders = {}\n",
        "for column in df.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "X = df.iloc[:, :-1].values  # Features\n",
        "y = df.iloc[:, -1].values   # Alvo\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "bdxUeIR2fx-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Número de amostras: {df.shape[0]}\")\n",
        "print(f\"Número de features: {df.shape[1] - 1}\")\n",
        "print(f\"Número de classes na variável alvo: {len(set(y))}\")\n"
      ],
      "metadata": {
        "id": "0jAyCwSUdRUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Desenvolvimento do modelo\n"
      ],
      "metadata": {
        "id": "lxcIOv5TeY7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(X_train.shape[1],)))\n"
      ],
      "metadata": {
        "id": "MElmr2iTeZJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Compilação do modelo\n"
      ],
      "metadata": {
        "id": "H8pxOAdteZS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Accuracy, AUC\n",
        "\n",
        "def f1_score_metric(y_true, y_pred):\n",
        "    y_pred = tf.round(y_pred)\n",
        "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, 'float'), axis=0)\n",
        "    precision = tp / (tf.reduce_sum(tf.cast(y_pred, 'float'), axis=0) + tf.keras.backend.epsilon())\n",
        "    recall = tp / (tf.reduce_sum(tf.cast(y_true, 'float'), axis=0) + tf.keras.backend.epsilon())\n",
        "    f1_score = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
        "    return tf.reduce_mean(f1_score)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy', AUC(name='auc'), f1_score_metric])\n"
      ],
      "metadata": {
        "id": "T3YEFIk4eZfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Treinamento do modelo\n"
      ],
      "metadata": {
        "id": "PYl-bpP8elVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, batch_size=10, validation_split=0.2, verbose=2)\n"
      ],
      "metadata": {
        "id": "Om_2DoFVelhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Avaliação do Modelo\n"
      ],
      "metadata": {
        "id": "C46y8dmJeltP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Acurácia no conjunto de teste: {evaluation[1]:.4f}\")\n",
        "print(f\"AUC no conjunto de teste: {evaluation[2]:.4f}\")\n",
        "print(f\"F1 Score no conjunto de teste: {evaluation[3]:.4f}\")\n"
      ],
      "metadata": {
        "id": "B15dQ_B9el5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}